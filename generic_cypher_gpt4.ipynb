{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUDi5el-l8d8",
        "outputId": "9104694a-4f9e-4c3d-a66d-7c013ad333c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.27.6)\n",
            "Requirement already satisfied: neo4j in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (5.8.0)\n",
            "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0.0)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (2.28.1)\n",
            "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: pytz in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from neo4j) (2022.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install openai neo4j python-dotenv\n",
        "\n",
        "import os, dotenv\n",
        "\n",
        "dotenv_file = dotenv.find_dotenv()\n",
        "dotenv.load_dotenv(dotenv_file)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NYILquGHZrd7"
      },
      "source": [
        "# Generating Cypher queries with GPT-4 on any graphÂ schema\n",
        "\n",
        "Large language models have a great potential to translate natural language into query language. For example, some people like to use GPT models to translate text to SQL, while others want to use GPT models to construct SPARQL queries. Personally, I prefer exploring how to translate natural language to Cypher query language.\n",
        "In my experiments, I have noticed there are two approaches to developing an LLM flow that constructs Cypher statements. One option is to provide example queries in the prompt or use the examples to finetune an LLM model. However, the limitation of this approach is that it requires some work to produce the Cypher examples. Therefore, the example Cypher queries must be generated for each graph schema. On the other hand, we can provide an LLM directly with schema information and let it construct Cypher statements based on graph schema information alone. Using the second approach, we could develop a generic Cypher statement model to produce Cypher statements for any input graph schema, as we eliminate the need for any additional work like generating example Cypher statements.\n",
        "This blog post aims to show you how to implement a Cypher statement-generating model by providing only the graph schema information. We will evaluate the model's Cypher construction capabilities on three graphs with different graph schemas. Currently, the only model I recommend to generate Cypher statements based on only the provided graph schema is GPT-4. Other models like GPT-3.5-turbo or text-davinci-003 aren't that great, and I have yet to find an open-source LLM model that would be good at following instructions in the prompt as well as GPT-4.\n",
        "## Experiment Setup\n",
        "I have implemented a Python class that connects to a Neo4j instance and fetches the schema information when initialized. The graph schema information can then be used as input to GPT-4 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "67N5Q5-CmuG8"
      },
      "outputs": [],
      "source": [
        "node_properties_query = \"\"\"\n",
        "CALL apoc.meta.data()\n",
        "YIELD label, other, elementType, type, property\n",
        "WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
        "WITH label AS nodeLabels, collect(property) AS properties\n",
        "RETURN {labels: nodeLabels, properties: properties} AS output\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "rel_properties_query = \"\"\"\n",
        "CALL apoc.meta.data()\n",
        "YIELD label, other, elementType, type, property\n",
        "WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"relationship\"\n",
        "WITH label AS nodeLabels, collect(property) AS properties\n",
        "RETURN {type: nodeLabels, properties: properties} AS output\n",
        "\"\"\"\n",
        "\n",
        "rel_query = \"\"\"\n",
        "CALL apoc.meta.data()\n",
        "YIELD label, other, elementType, type, property\n",
        "WHERE type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
        "RETURN {source: label, relationship: property, target: other} AS output\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IHY0Kt2-mFFq"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "from neo4j.exceptions import CypherSyntaxError\n",
        "import openai\n",
        "\n",
        "\n",
        "def schema_text(node_props, rel_props, rels):\n",
        "    return f\"\"\"\n",
        "  This is the schema representation of the Neo4j database.\n",
        "  Node properties are the following:\n",
        "  {node_props}\n",
        "  Relationship properties are the following:\n",
        "  {rel_props}\n",
        "  Relationship point from source to target nodes\n",
        "  {rels}\n",
        "  Make sure to respect relationship types and directions\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "class Neo4jGPTQuery:\n",
        "    def __init__(self, url, user, password, database, openai_api_key):\n",
        "        self.driver = GraphDatabase.driver(url, auth=(user, password), database=database)\n",
        "        openai.api_key = openai_api_key\n",
        "        # construct schema\n",
        "        self.schema = self.generate_schema()\n",
        "\n",
        "\n",
        "    def generate_schema(self):\n",
        "        node_props = self.query_database(node_properties_query)\n",
        "        rel_props = self.query_database(rel_properties_query)\n",
        "        rels = self.query_database(rel_query)\n",
        "        return schema_text(node_props, rel_props, rels)\n",
        "\n",
        "    def refresh_schema(self):\n",
        "        self.schema = self.generate_schema()\n",
        "\n",
        "    def get_system_message(self):\n",
        "        return f\"\"\"\n",
        "        Task: Generate Cypher queries to query a Neo4j graph database based on the provided schema definition.\n",
        "        Instructions:\n",
        "        Use only the provided relationship types and properties.\n",
        "        Do not use any other relationship types or properties that are not provided.\n",
        "        Return only Cypher code and no explanations or apologies.\n",
        "        Schema:\n",
        "        {self.schema}\n",
        "        \"\"\"\n",
        "\n",
        "    def query_database(self, neo4j_query, params={}):\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(neo4j_query, params)\n",
        "            output = [r.values() for r in result]\n",
        "            output.insert(0, result.keys())\n",
        "            return output\n",
        "\n",
        "    def construct_cypher(self, question, history=None):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": self.get_system_message()},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ]\n",
        "        # Used for Cypher healing flows\n",
        "        if history:\n",
        "            messages.extend(history)\n",
        "\n",
        "        completions = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0.0,\n",
        "            max_tokens=1000,\n",
        "            messages=messages\n",
        "        )\n",
        "        return completions.choices[0].message.content\n",
        "\n",
        "    def run(self, question, history=None, retry=False):\n",
        "        # Construct Cypher statement\n",
        "        cypher = self.construct_cypher(question, history)\n",
        "        print(cypher)\n",
        "        try:\n",
        "            return self.query_database(cypher)\n",
        "        # Self-healing flow\n",
        "        except CypherSyntaxError as e:\n",
        "            # If out of retries\n",
        "            if not retry:\n",
        "              return \"Invalid Cypher syntax\"\n",
        "        # Self-healing Cypher flow by\n",
        "        # providing specific error to GPT-4\n",
        "            print(\"Retrying\")\n",
        "            return self.run(\n",
        "                question,\n",
        "                [\n",
        "                    {\"role\": \"assistant\", \"content\": cypher},\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"\"\"This query returns an error: {str(e)} \n",
        "                        Give me a improved query that works without any explanations or apologies\"\"\",\n",
        "                    },\n",
        "                ],\n",
        "                retry=False\n",
        "            )\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### I am using my infamous Citation database from Bloom training here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NZTTW3TkpKFY"
      },
      "outputs": [],
      "source": [
        "demo_db = Neo4jGPTQuery(\n",
        "    url=\"bolt://localhost:7687\",\n",
        "    user=\"neo4j\",\n",
        "    password=\"Abcd-1234\",\n",
        "    database=\"citation\",\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyBNV92QqeUn",
        "outputId": "fca146ab-ac24-4abc-9d6b-3db3db0d4f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MATCH (a:Article)\n",
            "RETURN a.title\n",
            "ORDER BY a.n_citation DESC\n",
            "LIMIT 1;\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[['a.title'], ['Seizing Power: Shaders and Storytellers']]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_db.run(\"\"\"\n",
        "What is the title of the most cited Article ? This report will show only the first value of the first row returned.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MATCH (a:Article)\n",
            "RETURN a.year AS category, count(a) AS value\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[['category', 'value'],\n",
              " [2006, 7536],\n",
              " [2009, 817],\n",
              " [2003, 3678],\n",
              " [2002, 3612],\n",
              " [1998, 1620],\n",
              " [1999, 1446],\n",
              " [2011, 1162],\n",
              " [2005, 5056],\n",
              " [1994, 209],\n",
              " [2000, 1985],\n",
              " [2004, 5064],\n",
              " [2001, 2719],\n",
              " [1993, 213],\n",
              " [1997, 902],\n",
              " [2013, 959],\n",
              " [2012, 1935],\n",
              " [2014, 2040],\n",
              " [1991, 138],\n",
              " [1996, 243],\n",
              " [2008, 607],\n",
              " [2010, 812],\n",
              " [1990, 162],\n",
              " [1976, 118],\n",
              " [1978, 115],\n",
              " [1992, 129],\n",
              " [1983, 83],\n",
              " [1960, 53],\n",
              " [1973, 93],\n",
              " [1988, 113],\n",
              " [2015, 2075],\n",
              " [1979, 77],\n",
              " [1972, 116],\n",
              " [1995, 228],\n",
              " [1985, 94],\n",
              " [1977, 83],\n",
              " [1974, 91],\n",
              " [1980, 49],\n",
              " [1959, 42],\n",
              " [1981, 85],\n",
              " [1975, 80],\n",
              " [2007, 640],\n",
              " [1982, 81],\n",
              " [1989, 198],\n",
              " [1962, 201],\n",
              " [1969, 142],\n",
              " [1987, 81],\n",
              " [1961, 166],\n",
              " [1984, 90],\n",
              " [2016, 2308],\n",
              " [1964, 169],\n",
              " [1971, 69],\n",
              " [1963, 180],\n",
              " [1970, 147],\n",
              " [1986, 76],\n",
              " [1965, 154],\n",
              " [1958, 19],\n",
              " [1966, 145],\n",
              " [1968, 133],\n",
              " [1967, 150],\n",
              " [2017, 168]]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_db.run(\"\"\"\n",
        "Number of articles per year ? A pie chart expects two fields: a category and a value.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is an example of a Sankey chart using the provided data model:\n",
            "\n",
            "```\n",
            "MATCH (a:Author)-[r:CO_AUTHOR]->(b:Author)\n",
            "WHERE r.collaborations > 5\n",
            "WITH a, b, r.collaborations AS collaborations\n",
            "RETURN a.name AS source, b.name AS target, SUM(collaborations) AS value\n",
            "```\n",
            "\n",
            "This query will return a set of nodes and weighted relationships between authors who have collaborated on more than 5 articles. The resulting data can be used to create a Sankey chart that shows the flow of collaborations between authors. The \"source\" and \"target\" nodes will be the author names, and the \"value\" will be the number of collaborations between them.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Invalid Cypher syntax'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_db.run(\"\"\"\n",
        "Provide a good example of a sankey chart using my data model ? A Sankey chart expects Neo4j nodes and weighted relationships.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMV47wMTNlwFnmIA1EX1mSX",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
